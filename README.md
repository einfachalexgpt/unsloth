
<div align="center">

  <a href="https://unsloth.ai"><picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20logo%20white%20text.png">
    <source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20logo%20black%20text.png">
    <img alt="unsloth logo" src="https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20logo%20black%20text.png" height="110" style="max-width: 100%;">
  </picture></a>
  
<a href="https://colab.research.google.com/drive/1Ys44kVvmeZtnICzWz0xgpRnrIOjZAuxp?usp=sharing"><img src="https://raw.githubusercontent.com/unslothai/unsloth/main/images/start free finetune button.png" height="48"></a>
<a href="https://discord.gg/unsloth"><img src="https://raw.githubusercontent.com/unslothai/unsloth/main/images/Discord button.png" height="48"></a>
<a href="https://ko-fi.com/unsloth"><img src="https://raw.githubusercontent.com/unslothai/unsloth/main/images/buy me a coffee button.png" height="48"></a>

### Feintune Llama 3.1, Mistral, Phi-3.5 & Gemma 2-5x schneller mit 80% weniger Speicher!

![](https://i.ibb.co/sJ7RhGG/image-41.png)

</div>

## ‚ú® Kostenloses Feintuning

Alle Notebooks sind **anf√§ngerfreundlich**! F√ºge deinen Datensatz hinzu, klicke auf ‚ÄûRun All‚Äú, und du erh√§ltst ein 2x schnelleres feingetuntes Modell, das in GGUF, Ollama, vLLM oder auf Hugging Face exportiert werden kann.

| Unsloth unterst√ºtzt | Kostenlose Notebooks | Leistung | Speicherverbrauch |
|-----------|---------|--------|----------|
| **Llama 3.1 (8B)**      | [‚ñ∂Ô∏è Kostenlos starten](https://colab.research.google.com/drive/1Ys44kVvmeZtnICzWz0xgpRnrIOjZAuxp?usp=sharing)               | 2x schneller | 60% weniger |
| **Phi-3.5 (mini)** | [‚ñ∂Ô∏è Kostenlos starten](https://colab.research.google.com/drive/1lN6hPQveB_mHSnTOYifygFcrO8C1bxq4?usp=sharing)               | 2x schneller | 50% weniger |
| **Gemma 2 (9B)**      | [‚ñ∂Ô∏è Kostenlos starten](https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing)               | 2x schneller | 63% weniger |
| **Mistral Nemo (12B)** | [‚ñ∂Ô∏è Kostenlos starten](https://colab.research.google.com/drive/17d3U-CAIwzmbDRqbZ9NnpHxCkmXB6LZ0?usp=sharing)               | 2x schneller | 60% weniger |
| **Ollama**     | [‚ñ∂Ô∏è Kostenlos starten](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)               | 1.9x schneller | 43% weniger |
| **Mistral v0.3 (7B)**    | [‚ñ∂Ô∏è Kostenlos starten](https://colab.research.google.com/drive/1_yNCks4BTD5zOnjozppphh5GzMFaMKq_?usp=sharing)               | 2.2x schneller | 73% weniger |
| **ORPO**     | [‚ñ∂Ô∏è Kostenlos starten](https://colab.research.google.com/drive/11t4njE3c4Lxl-07OD8lJSMKkfyJml3Tn?usp=sharing)               | 1.9x schneller | 43% weniger |
| **DPO Zephyr**     | [‚ñ∂Ô∏è Kostenlos starten](https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing)               | 1.9x schneller | 43% weniger |

- **Kaggle Notebooks** f√ºr [Llama 3.1 (8B)](https://www.kaggle.com/danielhanchen/kaggle-llama-3-1-8b-unsloth-notebook), [Gemma 2 (9B)](https://www.kaggle.com/code/danielhanchen/kaggle-gemma-7b-unsloth-notebook/), [Mistral (7B)](https://www.kaggle.com/code/danielhanchen/kaggle-mistral-7b-unsloth-notebook)
- Starte [Llama 3.1 Gespr√§chsnotebook](https://colab.research.google.com/drive/15OyFkGoCImV9dSsewU1wa2JuKB4-mDE_?usp=sharing) und [Mistral v0.3 ChatML](https://colab.research.google.com/drive/15F1xyn8497_dUbxZP4zWmPZ3PJx1Oymv?usp=sharing)
- Dieses [Textvervollst√§ndigungsnotebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing) dient der fortgesetzten Vorab-Training / Rohtext
- Dieses [fortgesetzte Vorab-Training Notebook](https://colab.research.google.com/drive/1tEd1FrOXWMnCU9UIvdYhs61tkxdMuKZu?usp=sharing) ist f√ºr das Lernen einer anderen Sprache
- Klicke [hier](https://github.com/unslothai/unsloth/wiki) f√ºr die detaillierte Dokumentation von Unsloth.

## ü¶• Unsloth.ai Neuigkeiten
- üì£ NEU! [Llama 3.1 Gespr√§chsnotebook](https://colab.research.google.com/drive/15OyFkGoCImV9dSsewU1wa2JuKB4-mDE_?usp=sharing) umfasst jetzt Training nur auf Ausgaben (erh√∂hte Genauigkeit), Standardisierung nach ShareGPT und mehr!
- üì£ NEU! [Phi-3.5 (mini)](https://colab.research.google.com/drive/1lN6hPQveB_mHSnTOYifygFcrO8C1bxq4?usp=sharing) wird jetzt unterst√ºtzt.
- üì£ NEU! `pip install unsloth` funktioniert jetzt! Besuche [pypi](https://pypi.org/project/unsloth/) f√ºr weitere Informationen! Dies erm√∂glicht Installationen ohne git pull. Verwende `pip install unsloth[colab-new]` f√ºr Installationen ohne Abh√§ngigkeiten.
- üì£ NEU! [Gemma-2-2b](https://colab.research.google.com/drive/1weTpKOjBZxZJ5PQ-Ql8i6ptAY2x-FWVA?usp=sharing) wird jetzt unterst√ºtzt! Probiere [Chat-Schnittstelle](https://colab.research.google.com/drive/1i-8ESvtLRGNkkUQQr_-z_rcSAIo9c3lM?usp=sharing) aus!
- üì£ NEU! [Llama 3.1 8b, 70b](https://colab.research.google.com/drive/1Ys44kVvmeZtnICzWz0xgpRnrIOjZAuxp?usp=sharing) & [Mistral Nemo-12b](https://colab.research.google.com/drive/17d3U-CAIwzmbDRqbZ9NnpHxCkmXB6LZ0?usp=sharing) werden beide in den Basis- und Instruct-Versionen unterst√ºtzt.

<details>
  <summary>Klicke f√ºr weitere Neuigkeiten</summary>
  
- üì£ NEU! [Gemma-2-9b](https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing) und Gemma-2-27b werden jetzt unterst√ºtzt.
- üì£ AKTUALISIERT! [Phi-3 mini](https://colab.research.google.com/drive/1hhdhBa1j_hsymiW9m-WzxQtgqTH_NHqi?usp=sharing) Modell aktualisiert. [Phi-3 Medium](https://colab

.research.google.com/drive/1hhdhBa1j_hsymiW9m-WzxQtgqTH_NHqi?usp=sharing) jetzt 2x schneller im Feintuning.
- üì£ NEU! Fortgesetztes Pretraining [Notebook](https://colab.research.google.com/drive/1tEd1FrOXWMnCU9UIvdYhs61tkxdMuKZu?usp=sharing) f√ºr andere Sprachen wie Koreanisch.
- üì£ NEU! Qwen2 wird jetzt unterst√ºtzt.
- üì£ [Mistral v0.3 Basis](https://colab.research.google.com/drive/1_yNCks4BTD5zOnjozppphh5GzMFaMKq_?usp=sharing) und [Mistral v0.3 Instruct] sind da.
- üì£ [ORPO Unterst√ºtzung](https://colab.research.google.com/drive/11t4njE3c4Lxl-07OD8lJSMKkfyJml3Tn?usp=sharing) jetzt verf√ºgbar + [2x schnellere Inferenz](https://colab.research.google.com/drive/1aqlNQi7MMJbynFDyOQteD2t0yVfjb9Zh?usp=sharing) f√ºr alle unsere Modelle hinzugef√ºgt.
- üì£ Wir haben den Speicherverbrauch um [weitere 30% gesenkt](https://unsloth.ai/blog/long-context) und unterst√ºtzen jetzt [4x l√§ngere Kontextfenster](https://unsloth.ai/blog/long-context).

</details>

## üîó Links und Ressourcen
| Typ                            | Links                               |
| ------------------------------- | --------------------------------------- |
| üìö **Dokumentation & Wiki**              | [Lies unsere Dokumentation](https://docs.unsloth.ai) |
| <img height="14" src="https://upload.wikimedia.org/wikipedia/commons/6/6f/Logo_of_Twitter.svg" />&nbsp; **Twitter (aka X)**              |  [Folge uns auf X](https://twitter.com/unslothai)|
| üíæ **Installation**               | [unsloth/README.md](https://github.com/unslothai/unsloth/tree/main#installation-instructions)|
| ü•á **Benchmarking**                   | [Leistungstabellen](https://github.com/unslothai/unsloth/tree/main#-performance-benchmarking)
| üåê **Ver√∂ffentlichte Modelle**            | [Unsloth Releases](https://huggingface.co/unsloth)|
| ‚úçÔ∏è **Blog**                    | [Lies unsere Blogs](https://unsloth.ai/blog)|

## ‚≠ê Hauptmerkmale
- Alle Kernels sind in [OpenAI's Triton](https://openai.com/research/triton) Sprache geschrieben. **Manuelle Backprop-Engine**.
- **0% Verlust an Genauigkeit** - keine Approximation - alles exakt.
- Keine √Ñnderung der Hardware n√∂tig. Unterst√ºtzt NVIDIA GPUs seit 2018+. Mindestanforderung CUDA 7.0 (V100, T4, Titan V, RTX 20, 30, 40x, A100, H100, L40 usw.). [√úberpr√ºfe deine GPU](https://developer.nvidia.com/cuda-gpus). GTX 1070, 1080 funktioniert, ist aber langsamer.
- Funktioniert auf **Linux** und **Windows** via WSL.
- Unterst√ºtzt 4bit und 16bit QLoRA / LoRA Feintuning via [bitsandbytes](https://github.com/TimDettmers/bitsandbytes).
- Open Source-Training 5x schneller - siehe [Unsloth Pro](https://unsloth.ai/) f√ºr bis zu **30x schnelleres Training**!
- Wenn du ein Modell mit ü¶•Unsloth trainiert hast, kannst du diesen coolen Sticker verwenden! &nbsp; <img src="https://raw.githubusercontent.com/unslothai/unsloth/main/images/made with unsloth.png" height="50" align="center" />

## ü•á Leistungsmessungen
- F√ºr die vollst√§ndige Liste der **reproduzierbaren** Leistungstabellen, [gehe zu unserer Website](https://unsloth.ai/blog/mistral-benchmark#Benchmark%20tables).

| 1 A100 40GB  | ü§óHugging Face | Flash Attention | ü¶•Unsloth Open Source | ü¶•[Unsloth Pro](https://unsloth.ai/pricing) |
|--------------|--------------|-----------------|---------------------|-----------------|
| Alpaca       | 1x           | 1.04x           | 1.98x               | **15.64x**      |
| LAION Chip2  | 1x           | 0.92x           | 1.61x               | **20.73x**      |
| OASST        | 1x           | 1.19x           | 2.17x               | **14.83x**      |
| Slim Orca    | 1x           | 1.18x           | 2.22x               | **14.82x**      |

- Benchmarking-Tabelle unten wurde von [ü§óHugging Face](https://huggingface.co/blog/unsloth-trl) durchgef√ºhrt.

| Kostenloses Colab T4 | Datensatz | ü§óHugging Face | Pytorch 2.1.1 | ü¶•Unsloth | ü¶• VRAM Reduktion |
| --- | --- | --- | --- | --- | --- |
| Llama-2 7b | OASST | 1x | 1.19x | 1.95x | -43.3% |
| Mistral 7b | Alpaca | 1x | 1.07x | 1.56x | -13.7% |
| Tiny Llama 1.1b | Alpaca | 1x | 2.06x | 3.87x | -73.8% |
| DPO mit Zephyr | Ultra Chat | 1x | 1.09x | 1.55x | -18.6% |

![](https://i.ibb.co/sJ7RhGG/image-41.png)

## üíæ Installationsanweisungen

### Conda Installation
`‚ö†Ô∏è Verwende Conda nur, wenn du es installiert hast. Wenn nicht, verwende Pip.` W√§hle `pytorch-cuda=11.8,12.1` f√ºr CUDA 11.8 oder CUDA 12.1. Wenn du `mamba` hast, verwende `mamba` anstelle von `conda` f√ºr eine schnellere L√∂sung. Wir unterst√ºtzen `python=3.10,3.11,3.12`.
```bash
conda create --name unsloth_env \
    python=3.11 \
    pytorch-cuda=12.1 \
    pytorch cudatoolkit xformers -c pytorch -c nvidia -c xformers \
    -y
conda activate unsloth_env

pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"
pip install --no-deps trl peft accelerate bitsandbytes
```

<details>
  <summary>Wenn du Conda in einer Linux-Umgebung installieren m√∂chtest, <a href="https://docs.anaconda.com/miniconda/">lies hier</a>, oder f√ºhre den folgenden Befehl aus üîΩ</summary>
  
  ```bash
  mkdir -p ~/miniconda3
  wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh
  bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
  rm -rf ~/miniconda3/miniconda.sh
  ~/miniconda3/bin/conda init bash
  ~/miniconda3/bin/conda init zsh
  ```
</details>

### Pip Installation
`‚ö†Ô∏èVerwende dies **NICHT**, wenn du Conda hast.` Pip ist etwas komplizierter, da es Abh√§ngigkeitsprobleme gibt. Der Pip-Befehl unterscheidet sich f√ºr `torch 2.2,2.3,2.4` und CUDA-Versionen.

Im Allgemeinen, wenn du `torch 2.4` und `CUDA 12.1` hast, verwende:
```bash
pip install --upgrade pip
pip install "unsloth[cu121-torch240] @ git+https://github.com/unslothai/unsloth.git"
```

Oder f√ºhre den folgenden Befehl in einem Terminal aus, um den optionalen Pip-Installationsbefehl zu erhalten:
```bash
wget -qO- https://raw.githubusercontent.com/unslothai/unsloth/main/unsloth/_auto_install.py | python -
```

Oder f√ºhre den folgenden Befehl manuell in einem Python-REPL aus:
```python
try: import torch
except: raise ImportError("Installiere torch via `pip install torch`")
from packaging.version import Version as V
v = V(torch.__version__)
cuda = str(torch.version.cuda)
is_ampere = torch.cuda.get_device_capability()[0] >= 8
if cuda !=

 "12.1" and cuda != "11.8": raise RuntimeError(f"CUDA = {cuda} nicht unterst√ºtzt!")
if   v <= V('2.1.0'): raise RuntimeError(f"Torch = {v} zu alt!")
elif v <= V('2.1.1'): x = 'cu{}{}-torch211'
elif v <= V('2.1.2'): x = 'cu{}{}-torch212'
elif v  < V('2.3.0'): x = 'cu{}{}-torch220'
elif v  < V('2.4.0'): x = 'cu{}{}-torch230'
elif v  < V('2.5.0'): x = 'cu{}{}-torch240'
else: raise RuntimeError(f"Torch = {v} zu neu!")
x = x.format(cuda.replace(".", ""), "-ampere" if is_ampere else "")
print(f'pip install --upgrade pip && pip install "unsloth[{x}] @ git+https://github.com/unslothai/unsloth.git"')
```

Danach, √ºberpr√ºfe ob `nvcc`, `xformers` und `bitsandbytes` erfolgreich installiert wurden. Falls nicht, installiere sie einzeln, bis sie funktionieren, und installiere danach Unsloth.
```bash
nvcc
python -m xformers.info
python -m bitsandbytes
```

## üìú [Dokumentation](https://docs.unsloth.ai)
- Besuche unsere offizielle [Dokumentation](https://docs.unsloth.ai) f√ºr das Speichern in GGUF, Checkpointing, Evaluation und mehr!
- Wir unterst√ºtzen Huggingface's TRL, Trainer, Seq2SeqTrainer oder sogar Pytorch-Code!
- Wir sind in den offiziellen Dokumenten von ü§óHugging Face vertreten! Schau dir die [SFT-Dokumentation](https://huggingface.co/docs/trl/main/en/sft_trainer#accelerate-fine-tuning-2x-using-unsloth) und die [DPO-Dokumentation](https://huggingface.co/docs/trl/main/en/dpo_trainer#accelerate-dpo-fine-tuning-using-unsloth) an.

```python
from unsloth import FastLanguageModel 
from unsloth import is_bfloat16_supported
import torch
from trl import SFTTrainer
from transformers import TrainingArguments
from datasets import load_dataset
max_seq_length = 2048 # Unterst√ºtzt RoPE Scaling intern, w√§hle also eine beliebige L√§nge!
# Lade den LAION-Datensatz
url = "https://huggingface.co/datasets/laion/OIG/resolve/main/unified_chip2.jsonl"
dataset = load_dataset("json", data_files = {"train" : url}, split = "train")

# 4bit vorquantisierte Modelle, die wir unterst√ºtzen, f√ºr 4x schnelleres Herunterladen + keine OOMs.
fourbit_models = [
    "unsloth/mistral-7b-v0.3-bnb-4bit",      # Neues Mistral v3 2x schneller!
    "unsloth/mistral-7b-instruct-v0.3-bnb-4bit",
    "unsloth/llama-3-8b-bnb-4bit",           # Llama-3 15-Billionen-Token-Modell 2x schneller!
    "unsloth/llama-3-8b-Instruct-bnb-4bit",
    "unsloth/llama-3-70b-bnb-4bit",
    "unsloth/Phi-3-mini-4k-instruct",        # Phi-3 2x schneller!
    "unsloth/Phi-3-medium-4k-instruct",
    "unsloth/mistral-7b-bnb-4bit",
    "unsloth/gemma-7b-bnb-4bit",             # Gemma 2.2x schneller!
] # Weitere Modelle auf https://huggingface.co/unsloth

model, tokenizer = FastLanguageModel.from_pretrained(
    model_name = "unsloth/llama-3-8b-bnb-4bit",
    max_seq_length = max_seq_length,
    dtype = None,
    load_in_4bit = True,
)

# Mache Model-Patching und f√ºge schnelle LoRA-Gewichte hinzu
model = FastLanguageModel.get_peft_model(
    model,
    r = 16,
    target_modules = ["q_proj", "k_proj", "v_proj", "o_proj",
                      "gate_proj", "up_proj", "down_proj",],
    lora_alpha = 16,
    lora_dropout = 0, # Unterst√ºtzt jede Einstellung, aber = 0 ist optimiert
    bias = "none",    # Unterst√ºtzt jede Einstellung, aber = "none" ist optimiert
    # [NEU] "unsloth" nutzt 30% weniger VRAM, passt in 2x gr√∂√üere Batches!
    use_gradient_checkpointing = "unsloth", # True oder "unsloth" f√ºr sehr lange Kontexte
    random_state = 3407,
    max_seq_length = max_seq_length,
    use_rslora = False,  # Wir unterst√ºtzen Rank-Stabilized LoRA
    loftq_config = None, # Und LoftQ
)

trainer = SFTTrainer(
    model = model,
    train_dataset = dataset,
    dataset_text_field = "text",
    max_seq_length = max_seq_length,
    tokenizer = tokenizer,
    args = TrainingArguments(
        per_device_train_batch_size = 2,
        gradient_accumulation_steps = 4,
        warmup_steps = 10,
        max_steps = 60,
        fp16 = not is_bfloat16_supported(),
        bf16 = is_bfloat16_supported(),
        logging_steps = 1,
        output_dir = "outputs",
        optim = "adamw_8bit",
        seed = 3407,
    ),
)
trainer.train()

# Besuche https://github.com/unslothai/unsloth/wiki f√ºr fortgeschrittene Tipps wie:
# (1) Speichern in GGUF / Zusammenf√ºhren in 16bit f√ºr vLLM
# (2) Fortsetzung des Trainings von einem gespeicherten LoRA-Adapter
# (3) Hinzuf√ºgen einer Bewertungsschleife / OOMs
# (4) Angepasste Chat-Vorlagen
```

<a name="DPO"></a>
## DPO Unterst√ºtzung
DPO (Direct Preference Optimization), PPO, Reward Modelling funktionieren laut Tests von [Llama-Factory](https://github.com/hiyouga/LLaMA-Factory). Es gibt ein Google Colab Notebook f√ºr die Reproduktion von Zephyr auf Tesla T4 hier: [Notebook](https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing).

Wir sind in den offiziellen Dokumenten von ü§óHugging Face vertreten! Wir sind in den [SFT-Dokumenten](https://huggingface.co/docs/trl/main/en/sft_trainer#accelerate-fine-tuning-2x-using-unsloth) und den [DPO-Dokumenten](https://huggingface.co/docs/trl/main/en/dpo_trainer#accelerate-dpo-fine-tuning-using-unsloth)!

```python
from unsloth import FastLanguageModel, PatchDPOTrainer
from unsloth import is_bfloat16_supported
PatchDPOTrainer()
import torch
from transformers import TrainingArguments
from trl import DPOTrainer

model, tokenizer = FastLanguageModel.from_pretrained(
    model_name = "unsloth/zephyr-sft-bnb-4bit",
    max_seq_length = max_seq_length,
    dtype = None,
    load_in_4bit = True,
)

# Mache Model-Patching und f√ºge schnelle LoRA-Gewichte hinzu
model = FastLanguageModel.get_peft_model(
    model,
    r = 64,
    target_modules = ["q_proj", "k_proj", "v_proj", "o_proj",
                      "gate_proj", "up_proj", "down_proj",],
    lora_alpha = 64,
    lora_dropout = 0, # Unterst√ºtzt jede Einstellung, aber = 0 ist optimiert
    bias = "none",    # Unterst√ºtzt jede Einstellung, aber = "none" ist optimiert
    # [NEU] "unsloth" nutzt 30% weniger VRAM, passt in 2x gr√∂√üere Batches!
    use_gradient_checkpointing = "unsloth", # True oder "unsloth" f√ºr sehr lange Kontexte
    random_state = 3407,
    max_seq_length = max_seq_length,
)

dpo_trainer = DPOTrainer(
    model = model,
    ref_model = None,
    args = TrainingArguments(
        per_device_train_batch_size = 4,
        gradient_accumulation_steps = 8,
        warmup_ratio = 0.1,
        num_train_epochs = 3,
        fp16 = not is_bfloat16_supported(),
        bf16 = is_bfloat16_supported(),
        logging_steps = 1,
        optim = "adamw_8bit",
        seed = 42,
        output_dir = "outputs",
    ),
    beta = 0.1,
    train_dataset = DEIN_DATENSATZ_HIER,
    # eval_dataset = DEIN_DATENSATZ_HIER,
    tokenizer = tokenizer,
    max_length = 1024

,
    max_prompt_length = 512,
)
dpo_trainer.train()
```

## ü•á Detaillierte Benchmarking-Tabellen
- Klicke auf "Code" f√ºr vollst√§ndig reproduzierbare Beispiele.
- "Unsloth Equal" ist eine Vorschau unserer PRO-Version, mit entferntem Code. Alle Einstellungen und die Verlustkurve bleiben identisch.
- F√ºr die vollst√§ndige Liste der Benchmarking-Tabellen, [besuche unsere Website](https://unsloth.ai/blog/mistral-benchmark#Benchmark%20tables).

| 1 A100 40GB | ü§óHugging Face | Flash Attention 2 | ü¶•Unsloth Open | Unsloth Equal | Unsloth Pro | Unsloth Max |
|--------------|-------------|-------------|-----------------|--------------|---------------|-------------|
| Alpaca       | 1x          | 1.04x       | 1.98x           | 2.48x        | 5.32x         | **15.64x**      |
| Code | [Code](https://colab.research.google.com/drive/1u4dBeM-0vGNVmmO6X7cScAut-Hyt4KDF?usp=sharing) |    [Code](https://colab.research.google.com/drive/1fgTOxpMbVjloQBvZyz4lF4BacKSZOB2A?usp=sharing) |    [Code](https://colab.research.google.com/drive/1YIPY_18xm-K0iJDgvNkRoJsgkPMPAO3G?usp=sharing) |    [Code](https://colab.research.google.com/drive/1ANW8EFL3LVyTD7Gq4TkheC1Z7Rxw-rHp?usp=sharing) | | |
| Sekunden| 1040 | 1001 | 525 | 419 | 196 | 67  |
| Speicher MB| 18235 | 15365 | 9631 | 8525 | | |
| % gespart | | 15.74 | 47.18 | 53.25 | | | |

### Llama-Factory 3rd-Party-Benchmarking
- [Link zur Leistungstabelle](https://github.com/hiyouga/LLaMA-Factory/wiki/Performance-Comparison). TGS: Tokens pro GPU pro Sekunde. Modell: LLaMA2-7B. GPU: NVIDIA A100 * 1. Batch-Gr√∂√üe: 4. Gradient Accumulation: 2. LoRA Rank: 8. Maximale L√§nge: 1024.

| Methode | Bits | TGS | GRAM | Geschwindigkeit |
| --- | --- | --- | --- | --- |
| HF | 16 | 2392 | 18GB | 100% |
| HF+FA2 | 16 | 2954 | 17GB | 123% |
| Unsloth+FA2 | 16 | 4007 | 16GB | **168%** |
| HF | 4 | 2415 | 9GB | 101% |
| Unsloth+FA2 | 4 | 3726 | 7GB | **160%** |

### Leistung im Vergleich zwischen beliebten Modellen
<details>
  <summary>Klicke f√ºr spezifische Benchmarking-Tabellen (Mistral 7b, CodeLlama 34b usw.)</summary>
  
### Mistral 7b
| 1 A100 40GB | Hugging Face | Flash Attention 2 | Unsloth Open | Unsloth Equal | Unsloth Pro | Unsloth Max |
|--------------|-------------|-------------|-----------------|--------------|---------------|-------------|
| Mistral 7B Slim Orca  | 1x | 1.15x        | 2.15x        | 2.53x            | 4.61x         | **13.69x**         |
| Code | [Code](https://colab.research.google.com/drive/1mePk3KzwTD81hr5mcNcs_AX3Kbg_Ha0x?usp=sharing) | [Code](https://colab.research.google.com/drive/1dgHxjvTmX6hb0bPcLp26RXSE6_n9DKj7?usp=sharing) | [Code](https://colab.research.google.com/drive/1SKrKGV-BZoU4kv5q3g0jtE_OhRgPtrrQ?usp=sharing) | [Code](https://colab.research.google.com/drive/18yOiyX0T81mTwZqOALFSCX_tSAqju6aD?usp=sharing) | |
| Sekunden      | 1813        | 1571        | 842             | 718          | 393           | 132         |
| Speicher MB    | 32853       | 19385       | 12465           | 10271        |          |        |
| % gespart| | 40.99      | 62.06       | 68.74           |         |          |

### CodeLlama 34b
| 1 A100 40GB | Hugging Face | Flash Attention 2 | Unsloth Open | Unsloth Equal | Unsloth Pro | Unsloth Max |
|--------------|-------------|-------------|-----------------|--------------|---------------|-------------|
| Code Llama 34B   | OOM ‚ùå         | 0.99x        | 1.87x           | 2.61x        | 4.27x      | 12.82x      |
| Code | [‚ñ∂Ô∏è Code](https://colab.research.google.com/drive/1ykfz3BqrtC_AUFegCzUQjjfUNlxp6Otc?usp=sharing) | [Code](https://colab.research.google.com/drive/12ZypxQh7OC6kBXvWZI-5d05I4m-B_hoR?usp=sharing) | [Code](https://colab.research.google.com/drive/1gdHyAx8XJsz2yNV-DHvbHjR1iCef5Qmh?usp=sharing) | [Code](https://colab.research.google.com/drive/1fm7wqx9MJ0kRrwKOfmLkK1Rmw-pySahB?usp=sharing) | |
| Sekunden      | 1953  | 1982  | 1043  | 748   | 458   | 152   |
| Speicher MB    | 40000 | 33217 | 27413 | 22161 |       | |
| % gespart|    | 16.96| 31.47 | 44.60 |       | | |

### 1 Tesla T4

| 1 T4 16GB  | Hugging Face | Flash Attention | Unsloth Open    | Unsloth Pro Equal | Unsloth Pro   | Unsloth Max |
|--------------|-------------|-----------------|-----------------|---------------|---------------|-------------|
| Alpaca       | 1x          | 1.09x           | 1.69x           | 1.79x         | 2.93x          | **8.3x**        |
| Code | [‚ñ∂Ô∏è Code](https://colab.research.google.com/drive/1XpLIV4s8Bj5uryB-X2gqM88oRGHEGdaB?usp=sharing) |    [Code](https://colab.research.google.com/drive/1LyXu6CjuymQg6ddHX8g1dpUvrMa1nn4?usp=sharing) |    [Code](https://colab.research.google.com/drive/1gsv4LpY7C32otl1rgRo5wXTk4HIitXoM?usp=sharing) |    [Code](https://colab.research.google.com/drive/1VtULwRQwhEnVdNryjm27zXfdSM1tNfFK?usp=sharing) | | |
| Sekunden       | 1599        | 1468        | 942             | 894          | 545           | 193         |
| Speicher MB       | 7199        | 7059        | 6459            | 5443         |               |             |
| % gespart        |         | 1.94        | 10.28           | 24.39        |               | |

### 2 Tesla T4s via DDP

 | 2 T4 DDP | Hugging Face | Flash Attention | Unsloth Open | Unsloth Equal | Unsloth Pro | Unsloth Max |
|--------------|----------|-------------|-----------------|--------------|---------------|-------------|
| Alpaca       | 1x       | 0.99x       | 4.95x           | 4.44x        | 7.28x         | **20.61x**      |
| Code | [‚ñ∂Ô∏è Code](https://www.kaggle.com/danielhanchen/hf-original-alpaca-t4-ddp) |   [Code](https://www.kaggle.com/danielhanchen/hf-sdpa-alpaca-t4-ddp) |   [Code](https://www.kag

gle.com/danielhanchen/unsloth-alpaca-t4-ddp) | | |
| Sekunden       | 9882     | 9946        | 1996            | 2227         | 1357          | 480         |
| Speicher MB| 9176 | 9128 | 6904 | 6782 |  | |
| % gespart |     | 0.52 | 24.76 | 26.09 |  | | |
</details>

### Leistung im Vergleich auf 1 Tesla T4 GPU:
<details>
  <summary>Klicke f√ºr die Zeit, die f√ºr 1 Epoche ben√∂tigt wird</summary>

Eine Tesla T4 auf Google Colab
`bsz = 2, ga = 4, max_grad_norm = 0.3, num_train_epochs = 1, seed = 3047, lr = 2e-4, wd = 0.01, optim = "adamw_8bit", schedule = "linear", schedule_steps = 10`

| System | GPU | Alpaca (52K) | LAION OIG (210K) | Open Assistant (10K) | SlimOrca (518K) |
| --- | --- | --- | --- | --- | --- |
| Huggingface | 1 T4 | 23h 15m | 56h 28m | 8h 38m | 391h 41m |
| Unsloth Open | 1 T4 | 13h 7m (1.8x) | 31h 47m (1.8x) | 4h 27m (1.9x) | 240h 4m (1.6x) |
| Unsloth Pro | 1 T4 | 3h 6m (7.5x) | 5h 17m (10.7x) | 1h 7m (7.7x) | 59h 53m (6.5x) |
| Unsloth Max | 1 T4 | 2h 39m (8.8x) | 4h 31m (12.5x) | 0h 58m (8.9x) | 51h 30m (7.6x) |

**Spitzen-Speichernutzung**

| System | GPU | Alpaca (52K) | LAION OIG (210K) | Open Assistant (10K) | SlimOrca (518K) |
| --- | --- | --- | --- | --- | --- |
| Huggingface | 1 T4 | 7.3GB | 5.9GB | 14.0GB | 13.3GB |
| Unsloth Open | 1 T4 | 6.8GB | 5.7GB | 7.8GB | 7.7GB |
| Unsloth Pro | 1 T4 | 6.4GB | 6.4GB | 6.4GB | 6.4GB |
| Unsloth Max | 1 T4 | 11.4GB | 12.4GB | 11.9GB | 14.4GB |
</details>

<details>
  <summary>Klicke f√ºr Leistung im Vergleich auf 2 Tesla T4 GPUs via DDP:</summary>
**Zeit f√ºr 1 Epoche**

Zwei Tesla T4s auf Kaggle
`bsz = 2, ga = 4, max_grad_norm = 0.3, num_train_epochs = 1, seed = 3047, lr = 2e-4, wd = 0.01, optim = "adamw_8bit", schedule = "linear", schedule_steps = 10`

| System | GPU | Alpaca (52K) | LAION OIG (210K) | Open Assistant (10K) | SlimOrca (518K) * |
| --- | --- | --- | --- | --- | --- |
| Huggingface | 2 T4 | 84h 47m | 163h 48m | 30h 51m | 1301h 24m * |
| Unsloth Pro | 2 T4 | 3h 20m (25.4x) | 5h 43m (28.7x) | 1h 12m (25.7x) | 71h 40m (18.1x) * |
| Unsloth Max | 2 T4 | 3h 4m (27.6x) | 5h 14m (31.3x) | 1h 6m (28.1x) | 54h 20m (23.9x) * |

**Spitzen-Speichernutzung in einem Multi-GPU-System (2 GPUs)**

| System | GPU | Alpaca (52K) | LAION OIG (210K) | Open Assistant (10K) | SlimOrca (518K) * |
| --- | --- | --- | --- | --- | --- |
| Huggingface | 2 T4 | 8.4GB \| 6GB | 7.2GB \| 5.3GB | 14.3GB \| 6.6GB | 10.9GB \| 5.9GB * |
| Unsloth Pro | 2 T4 | 7.7GB \| 4.9GB | 7.5GB \| 4.9GB | 8.5GB \| 4.9GB | 6.2GB \| 4.7GB * |
| Unsloth Max | 2 T4 | 10.5GB \| 5GB | 10.6GB \| 5GB | 10.6GB \| 5GB | 10.5GB \| 5GB * |

* Slim Orca `bsz=1` f√ºr alle Benchmarks, da `bsz=2` zu OOM f√ºhrt. Wir k√∂nnen `bsz=2` handhaben, benchmarken es jedoch mit `bsz=1` f√ºr Konsistenz.
</details>

![](https://i.ibb.co/sJ7RhGG/image-41.png)
<br>

### Vielen Dank an
- [HuyNguyen-hust](https://github.com/HuyNguyen-hust) f√ºr die Erstellung von [RoPE Embeddings 28% schneller](https://github.com/unslothai/unsloth/pull/238)
- [RandomInternetPreson](https://github.com/RandomInternetPreson) f√ºr die Best√§tigung der WSL-Unterst√ºtzung
- [152334H](https://github.com/152334H) f√ºr experimentelle DPO-Unterst√ºtzung
- [atgctg](https://github.com/atgctg) f√ºr Syntax-Highlighting
```
